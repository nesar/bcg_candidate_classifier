#!/usr/bin/env python3
"""
Dynamic Sectors Plot for BCG Candidate Classifier

This module creates sector (donut) plots showing rank-based detection performance
from evaluation_results.csv files generated by the BCG candidate classifier.

Features:
- Single-target rank distribution visualization
- Multi-target rank distribution visualization
- Dynamic data loading from evaluation results
- Publication-quality donut charts with annotations
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from plot_config import setup_plot_style, COLORS, FONTS, SIZES, get_rank_colors


def load_evaluation_results(results_file):
    """Load and validate evaluation results CSV file."""
    if not os.path.exists(results_file):
        raise FileNotFoundError(f"Results file not found: {results_file}")

    df = pd.read_csv(results_file)

    # Validate required columns for rank analysis
    if 'bcg_rank' not in df.columns and 'multi_target_rank' not in df.columns:
        raise ValueError("Evaluation results must contain rank information (bcg_rank or multi_target_rank)")

    print(f"Loaded {len(df)} evaluation results")
    return df


def calculate_rank_statistics(df, rank_column='bcg_rank'):
    """
    Calculate rank-based statistics from evaluation results.

    Args:
        df: DataFrame with evaluation results
        rank_column: Name of the rank column ('bcg_rank' or 'multi_target_rank')

    Returns:
        tuple: (percentages, labels, accuracy)
    """
    if rank_column not in df.columns or df[rank_column].isna().all():
        # Return empty data if column not available
        return None, None, None

    ranks = df[rank_column].dropna()
    total = len(df)

    # Count successes by rank
    rank_1_count = len(ranks[ranks == 1])
    rank_2_count = len(ranks[ranks == 2])
    rank_3_count = len(ranks[ranks == 3])
    rank_rest_count = len(ranks[ranks > 3])

    # Calculate percentages
    rank_1_pct = (rank_1_count / total) * 100
    rank_2_pct = (rank_2_count / total) * 100
    rank_3_pct = (rank_3_count / total) * 100
    rank_rest_pct = (rank_rest_count / total) * 100

    percentages = [rank_1_pct, rank_2_pct, rank_3_pct, rank_rest_pct]
    labels = ["Rank 1", "Rank 2", "Rank 3", "Rest"]

    # Calculate top-3 accuracy
    top3_accuracy = (rank_1_count + rank_2_count + rank_3_count) / total * 100

    return percentages, labels, top3_accuracy


def improved_donut(ax, values, labels, title, success, if_legend):
    """
    Create an improved donut chart with annotations.

    Args:
        ax: Matplotlib axis
        values: List of percentages for each sector
        labels: List of labels for each sector
        title: Chart title
        success: Overall accuracy percentage
        if_legend: Whether to show legend
    """
    colors = plt.cm.Paired.colors
    wedges, _ = ax.pie(values, startangle=90, colors=colors, radius=1.05,
                       wedgeprops={'edgecolor':'white','linewidth':SIZES['linewidth_thin']})
    ax.add_artist(plt.Circle((0,0),0.65,fc='white'))
    ax.text(0,0, title + "\n" + f"Acc: {success:.1f}%",ha='center',va='center',fontsize=FONTS['title'])

    for i,(w,v) in enumerate(zip(wedges,values)):
        ang = (w.theta2 + w.theta1)/2
        x,y = np.cos(np.deg2rad(ang)), np.sin(np.deg2rad(ang))
        r = 1.01

        # Longer arrow for "Rest", slightly shorter for others
        if labels[i] == "Rest":
            arrow_len = 1.75

        elif labels[i] == "Rank 2":
            arrow_len = 1.2

        elif v < 12:
            arrow_len = 1.45
        else:
            arrow_len = None

        if arrow_len:

            if labels[i] == "Rest":

                x_edit = x - 0.15
                y_edit = y - 0.25

                ax.annotate(f"{labels[i]} ({v:.1f}%)",
                            xy=(r*x, r*y), xytext=(arrow_len*x_edit, arrow_len*y_edit),
                            ha='center', va='center', fontsize=FONTS['annotation'],
                            arrowprops=dict(arrowstyle='->', color=colors[i], lw=SIZES['linewidth'],
                                            shrinkA=0, shrinkB=2))


            else:
                ax.annotate(f"{labels[i]} ({v:.1f}%)",
                            xy=(r*x, r*y), xytext=(arrow_len*x, arrow_len*y),
                            ha='center', va='center', fontsize=FONTS['annotation'],
                            arrowprops=dict(arrowstyle='->', color=colors[i], lw=SIZES['linewidth'],
                                            shrinkA=0, shrinkB=2))


        else:
            ax.text(0.5*x, 0.85*y, f"{labels[i]} ({v:.1f}%)", ha='center', va='center', fontsize=FONTS['annotation'])

    legend_elems = [Patch(facecolor=colors[i], label=l) for i,l in enumerate(labels)]
    if if_legend:
        ax.legend(handles=legend_elems, loc='center left', bbox_to_anchor=(1,0.5),
                  fontsize=FONTS['legend'], frameon=True)


def format_config_text(config):
    """Format configuration dictionary into a readable text block for plot annotations.

    Args:
        config: Dictionary containing hyperparameters and BCG configuration

    Returns:
        Formatted string for display in text box
    """
    lines = []

    # Training parameters section
    if any(k in config for k in ['epochs', 'batch_size', 'lr']):
        lines.append("Training Parameters:")
        if 'epochs' in config:
            lines.append(f"  Epochs: {config['epochs']}")
        if 'batch_size' in config:
            lines.append(f"  Batch size: {config['batch_size']}")
        if 'lr' in config:
            lines.append(f"  Learning rate: {config['lr']}")

    # BCG Configuration section
    bcg_keys = ['dataset', 'additional_features', 'redmapper_probs', 'z_range',
                'delta_mstar_z_range', 'desprior_candidates', 'candidate_delta_mstar_range']
    if any(k in config for k in bcg_keys):
        if lines:
            lines.append("")
        lines.append("BCG Configuration:")
        if 'dataset' in config:
            lines.append(f"  Dataset: {config['dataset']}")
        if 'additional_features' in config:
            lines.append(f"  Additional features: {config['additional_features']}")
        if 'redmapper_probs' in config:
            lines.append(f"  RedMapper probs: {config['redmapper_probs']}")
        if 'z_range' in config:
            lines.append(f"  Redshift filter: {config['z_range']}")
        if 'delta_mstar_z_range' in config:
            lines.append(f"  Delta M* z filter: {config['delta_mstar_z_range']}")
        if 'desprior_candidates' in config:
            lines.append(f"  DESprior candidates: {config['desprior_candidates']}")
        if 'candidate_delta_mstar_range' in config:
            lines.append(f"  Candidate delta_mstar: {config['candidate_delta_mstar_range']}")

    return '\n'.join(lines) if lines else ""


def create_sectors_plot(results_file, output_dir=None, figsize=(14, 7), config=None):
    """
    Create sector plots from evaluation results.

    Args:
        results_file: Path to evaluation_results.csv
        output_dir: Directory to save plots (defaults to same dir as results)
        figsize: Figure size for the plot
        config: Optional dict with hyperparameters to display in text box

    Returns:
        fig: Matplotlib figure object
    """
    # Apply consistent plot style
    setup_plot_style()

    # Load data
    df = load_evaluation_results(results_file)

    # Set output directory
    if output_dir is None:
        output_dir = os.path.dirname(results_file)

    # Calculate statistics for single-target and multi-target
    single_values, single_labels, single_accuracy = calculate_rank_statistics(df, 'bcg_rank')
    multi_values, multi_labels, multi_accuracy = calculate_rank_statistics(df, 'multi_target_rank')

    # Check if we have data for both
    has_single = single_values is not None
    has_multi = multi_values is not None

    if not has_single and not has_multi:
        raise ValueError("No rank data available in evaluation results")

    # Create figure
    if has_single and has_multi:
        fig, axs = plt.subplots(1, 2, figsize=figsize)
        improved_donut(axs[0], single_values, single_labels, "Single-target", single_accuracy, True)
        improved_donut(axs[1], multi_values, multi_labels, "Multi-target", multi_accuracy, False)
    elif has_single:
        fig, ax = plt.subplots(1, 1, figsize=(figsize[0]/2, figsize[1]))
        improved_donut(ax, single_values, single_labels, "Single-target", single_accuracy, True)
    else:
        fig, ax = plt.subplots(1, 1, figsize=(figsize[0]/2, figsize[1]))
        improved_donut(ax, multi_values, multi_labels, "Multi-target", multi_accuracy, True)

    # Add hyperparameter text box if config is provided
    if config is not None:
        config_text = format_config_text(config)
        if config_text:
            # Add text box at the bottom of the figure
            fig.text(0.02, 0.02, config_text, fontsize=7, fontfamily='monospace',
                     verticalalignment='bottom', horizontalalignment='left',
                     bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.8, edgecolor='gray'))

    plt.tight_layout()
    # Adjust bottom margin to accommodate text box
    if config is not None:
        plt.subplots_adjust(bottom=0.22)

    # Save the plot
    output_file = os.path.join(output_dir, 'diagnostic_plots_sectors.png')
    plt.savefig(output_file, dpi=SIZES['dpi'], bbox_inches='tight')
    print(f"Sectors plot saved to: {output_file}")

    # Also save as PDF for publication quality
    pdf_file = os.path.join(output_dir, 'diagnostic_plots_sectors.pdf')
    plt.savefig(pdf_file, dpi=SIZES['dpi'], bbox_inches='tight')
    print(f"High-quality PDF saved to: {pdf_file}")

    # Print statistics summary
    print("\nSectors Plot Statistics:")
    if has_single:
        print(f"  Single-target Top-3 Accuracy: {single_accuracy:.1f}%")
        print(f"    Rank 1: {single_values[0]:.1f}%")
        print(f"    Rank 2: {single_values[1]:.1f}%")
        print(f"    Rank 3: {single_values[2]:.1f}%")
        print(f"    Rest: {single_values[3]:.1f}%")
    if has_multi:
        print(f"  Multi-target Top-3 Accuracy: {multi_accuracy:.1f}%")
        print(f"    Rank 1: {multi_values[0]:.1f}%")
        print(f"    Rank 2: {multi_values[1]:.1f}%")
        print(f"    Rank 3: {multi_values[2]:.1f}%")
        print(f"    Rest: {multi_values[3]:.1f}%")

    return fig


def main():
    """Command line interface for sectors plotting."""
    import argparse

    parser = argparse.ArgumentParser(description='Generate sector plots from BCG evaluation results')
    parser.add_argument('results_file', help='Path to evaluation_results.csv file')
    parser.add_argument('--output_dir', help='Output directory for plots (default: same as results file)')
    parser.add_argument('--figsize', nargs=2, type=float, default=[14, 7],
                       help='Figure size (width height) in inches')

    args = parser.parse_args()

    try:
        fig = create_sectors_plot(args.results_file, args.output_dir, tuple(args.figsize))
        plt.show()
    except Exception as e:
        print(f"Error creating sectors plot: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()