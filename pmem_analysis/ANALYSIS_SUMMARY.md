# PMEM Analysis Summary

## Overview

This analysis explores RedMapper membership probabilities (`p_mem`) from the `rm_member_catalogs/` directory and evaluates their potential for improving BCG (Brightest Cluster Galaxy) identification.

## Terminology

| Term | Symbol | Source | Description |
|------|--------|--------|-------------|
| **Members** | `p_mem` | rm_member_catalogs | RedMapper cluster membership probability |
| **Candidates** | `p_RM` | bcg_matched dataset | Candidate probability from BCG selection |

## Data Sources

| Dataset | Local Path | Cluster Path |
|---------|-----------|--------------|
| RM Member Catalogs | `/Users/nesar/.../rm_member_catalogs/` | `/lcrc/project/cosmo_ai/.../rm_member_catalogs/` |
| Priors | `prior_locations_more_info_PURGED_111925.csv` | Same filename on cluster |
| BCG Matched | `bcgs_3p8arcmin_clean_matched.csv` | N/A (generated by pipeline) |

## Key Findings

### Dataset Statistics
- **Total RM member entries**: 124,997
- **Clusters with RM data**: 1,784
- **Prior entries**: 37,694 from 1,937 clusters
- **Clusters in common**: 1,749

### Match Statistics
- **Match rate** (priors found in RM catalogs): **54.21%**
- **Total matched**: 19,250 out of 35,511 priors

### BCG Analysis (Key Result!)

| Metric | Value |
|--------|-------|
| Clusters where BCG found in RM data | 1,716 |
| **BCG p_mem mean** | **0.98** |
| **BCG p_mem median** | **1.00** |
| BCG p_mem std | 0.10 |
| **BCGs ranked #1 by p_mem** | **94.87%** |
| **BCGs in top-3 by p_mem** | **95.05%** |
| Mean BCG rank by p_mem | 2.38 |

**Critical Insight**: When sorting RM members by p_mem, the true BCG is ranked #1 in **~95% of cases**. This is an extremely strong signal!

### p_RM (Candidates) vs p_mem (Members) Comparison

| Metric | p_RM (Candidates) | p_mem (Members) |
|--------|-------------------|-----------------|
| Mean | 0.825 | 0.977 |
| Median | 0.942 | 1.000 |
| Std | 0.209 | 0.115 |

**Correlation Analysis:**
- **Pearson correlation**: 0.223 (weak positive)
- **Spearman correlation**: 0.350 (p < 1e-54)

**Agreement Analysis:**
| Category | Count | Percentage |
|----------|-------|------------|
| High Both (p_mem > 0.8, p_RM > 0.8) | 1,221 | 64.8% |
| Low Both (p_mem < 0.5, p_RM < 0.5) | 11 | 0.6% |
| High p_mem, Low p_RM | 153 | 8.1% |
| Low p_mem, High p_RM | 10 | 0.5% |

**Key Observations:**
1. **p_mem is more confident**: 98.4% of candidates have p_mem ≥ 0.5 vs 91% for p_RM
2. **p_mem is more extreme**: p_mem clusters at 1.0, while p_RM is more distributed
3. **Low correlation is informative**: The weak correlation (r=0.22) suggests p_mem and p_RM capture **different information** - this is good for ensemble approaches!
4. **Disagreements (8.1%)**: Cases where p_mem is high but p_RM is uncertain - these could be interesting edge cases to study

## Implications for BCG Classification

### Current Framework Context
The current classifier uses:
1. Image features (CNN-based)
2. delta_mstar (stellar mass offset)
3. RedMapper probabilities (already integrated as optional feature)
4. Spatial/positional information

### p_mem Uniqueness
The p_mem values are **per-member probabilities** from RedMapper's cluster membership algorithm, distinct from:
- `p_RM` in matched dataset (our candidate probability)
- `redmapper_probs` flag (binary indicator of using RM features)

## Brainstorming: Integration Strategies

### Strategy 1: Pre-filtering Candidates
**Approach**: Use p_mem > threshold to filter candidates before classification.
- **Pros**: Reduces false positives, faster inference
- **Cons**: May miss BCGs in edge cases (the 5% that aren't rank-1)
- **Implementation**: Add p_mem threshold parameter in `create_and_verify_bcg_dataset.py`

### Strategy 2: Additional Input Feature
**Approach**: Include p_mem as an additional feature alongside delta_mstar, rz, etc.
- **Pros**: Lets the model learn to weight p_mem appropriately
- **Cons**: Need to ensure p_mem is available at inference time
- **Implementation**: Add `p_mem` column to training data, modify `BCGDataset` class

### Strategy 3: Prior Weighting / Loss Weighting
**Approach**: Weight training samples by p_mem (high p_mem = more confident labels)
- **Pros**: Accounts for label uncertainty
- **Cons**: May bias toward high-p_mem cases
- **Implementation**: Modify loss function with sample weights

### Strategy 4: Ensemble / Bayesian Combination
**Approach**: Combine p_RM with p_mem using Bayesian framework:
```
P(BCG | image, p_mem) ∝ P(image | BCG) × P(BCG | p_mem)
```
- **Pros**: Principled probabilistic combination
- **Cons**: Requires calibration of both probability estimates
- **Implementation**: Post-processing step after classification

### Strategy 5: Candidate Ranking Refinement
**Approach**: Use p_mem to break ties or refine rankings when p_RM values are similar.
- **Pros**: Non-invasive, easy to implement
- **Cons**: Limited impact if classifier already confident
- **Implementation**: Post-processing in `evaluate.py`

### Strategy 6: Multi-Task Learning
**Approach**: Predict both BCG identity and p_mem from images.
- **Pros**: Regularization, potentially better generalization
- **Cons**: Increased model complexity
- **Implementation**: Add secondary prediction head

## Recommended Strategy

Based on the analysis, **Strategy 2 (Additional Input Feature)** combined with **Strategy 5 (Ranking Refinement)** appears most promising:

1. **Include p_mem as input feature**: The 95% rank-1 accuracy suggests p_mem is highly predictive
2. **Use p_mem for tie-breaking**: When p_RM outputs are close (e.g., within 5%), prefer higher p_mem candidate

This preserves the value of image-based classification while leveraging the strong p_mem signal.

## Files Generated

```
pmem_analysis/
├── analyze_pmem_data.py           # Main analysis script
├── cluster_analysis_results.csv   # Per-cluster analysis results
├── prm_vs_pmem.csv                # p_RM vs p_mem matched data
├── ANALYSIS_SUMMARY.md            # This summary
└── plots/
    ├── pmem_distribution.png      # Overall p_mem distributions
    ├── bcg_rank_by_pmem.png       # BCG ranking analysis
    ├── prm_vs_pmem.png            # p_RM vs p_mem comparison (6 panels)
    ├── cluster_detail_good_*.png  # Good cluster examples (3)
    ├── cluster_detail_bad_*.png   # Bad cluster examples (3)
    └── cluster_detail_random_*.png # Random cluster examples (6)
```

## Cluster Detail Plots

Each cluster detail plot shows 3 panels:
1. **Left**: Image overlay with Members (circles, colored by p_mem), Candidates (gray squares), Top candidate (red square), Top member (cyan circle)
2. **Middle**: p_mem distribution histogram with top candidates marked
3. **Right**: p_RM vs p_mem scatter for all matched candidates/members

### Selection Criteria:
| Category | Criteria | Count |
|----------|----------|-------|
| **Good** | n_matched > 5, p_mem > 0.9, rank = 1 | 3 |
| **Bad** | n_matched ≤ 3 OR p_mem < 0.5 OR rank > 3 | 3 |
| **Random** | Remaining clusters with valid data | 6 |

## Next Steps (Not Implemented)

1. **Add p_mem matching to data pipeline**: Modify `create_and_verify_bcg_dataset.py` to include p_mem
2. **Create p_mem-augmented training data**: Generate new CSV with p_mem column
3. **Modify model architecture**: Update `BCGDataset` to include p_mem feature
4. **Ablation study**: Compare classifier performance with/without p_mem
5. **Error analysis**: Examine the 5% of cases where BCG is not ranked #1 by p_mem

## Caveats

1. **Not all priors have p_mem matches**: 54% match rate means some candidates lack p_mem
2. **Coordinate matching tolerance**: Used 2 arcsec tolerance; may need adjustment
3. **BCG definition consistency**: Ensure BCG labels are consistent between datasets
