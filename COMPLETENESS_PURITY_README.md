# Completeness and Purity Analysis for BCG Classifier

## Overview

This module adds automatic computation and visualization of **completeness** and **purity** metrics as functions of:
1. **Redshift (z)**
2. **Delta M* z (delta_mstar_z)**

The analysis generates 4 subplots showing how these key performance metrics vary with these physical parameters.

## Definitions

### Completeness (Recall/Sensitivity)
The fraction of true BCGs that were successfully detected by the classifier.

**Formula**: `Completeness = (# of true BCGs detected within threshold) / (total # of true BCGs)`

- **For single-prediction models**: Completeness = (# images with distance_error ≤ threshold) / (total # images)
- **For multi-detection models (UQ)**: Completeness = (# images where at least one detection matches the true BCG) / (total # images)

### Purity (Precision)
The fraction of detected objects that are actually true BCGs.

**Formula**: `Purity = (# of correct detections) / (total # of detections)`

- **For single-prediction models**: Purity = Completeness (since we make exactly 1 prediction per image)
- **For multi-detection models (UQ)**: Purity accounts for multiple detections per image

## Integration with Pipeline

### Automatic Generation in `enhanced_full_run.py`

The completeness and purity plots are **automatically generated** when you run `enhanced_full_run.py`. They are created immediately after the diagnostic plots and sectors plots in Step 4.

**Generated Files**:
- `<output_dir>/completeness_purity_plots.png` - High-resolution PNG (300 DPI)
- `<output_dir>/completeness_purity_plots.pdf` - Publication-quality PDF (300 DPI)

**Location in Pipeline**: Step 4 - Diagnostic Plots Generation

### Testing on Existing Results

You can also run the completeness/purity analysis on **existing experimental results** without re-running the full pipeline:

```bash
# Run on a specific experiment directory
python test_completeness_purity.py ./trained_models/candidate_classifier_color_uq_run_20251027_120000/

# Or manually specify paths
python plot_completeness_purity.py \
    ./trained_models/experiment_name/evaluation_results/evaluation_results.csv \
    --output_dir ./trained_models/experiment_name/ \
    --bcg_csv /path/to/bcgs_3p8arcmin_clean_matched.csv \
    --distance_threshold 10.0 \
    --n_bins 10
```

## Requirements

### Input Data

1. **evaluation_results.csv** - Generated by `test.py`, must contain:
   - `z` (redshift) - automatically included if metadata is available
   - `distance_error` - distance between prediction and true BCG
   - `cluster_name` - cluster identifier
   - Optional: `n_detections`, `matches_any_target` (for UQ models)

2. **BCG CSV file** - Original BCG catalog containing:
   - `Cluster name` - to match with evaluation results
   - `delta_mstar_z` - stellar mass parameter

### Python Dependencies

All required packages are already installed:
- `numpy`
- `pandas`
- `matplotlib`
- `seaborn`

## Plot Description

The output consists of **4 subplots** (2×2 grid):

### Upper Left: Completeness vs Redshift
- Shows how detection completeness varies with redshift
- Green line with confidence bands
- Horizontal dashed line shows overall completeness

### Upper Right: Completeness vs Delta M* z
- Shows how detection completeness varies with stellar mass parameter
- Green line with confidence bands
- Horizontal dashed line shows overall completeness

### Lower Left: Purity vs Redshift
- Shows how detection purity varies with redshift
- Blue line with confidence bands
- For single-prediction models, displays note: "Purity = Completeness"

### Lower Right: Purity vs Delta M* z
- Shows how detection purity varies with stellar mass parameter
- Blue line with confidence bands
- For single-prediction models, displays note: "Purity = Completeness"

## Technical Details

### Binning Strategy

- Data is binned into `n_bins` equally-spaced bins (default: 10)
- Bin centers are used for plotting
- Samples with NaN values are excluded from the analysis

### Error Bars

Error bars represent binomial statistics:
```
error = sqrt(p * (1 - p) / n)
```
where `p` is the success rate and `n` is the number of samples in the bin.

### Multi-Detection Analysis (UQ Models)

For models with uncertainty quantification that generate multiple detections per image:
- **Completeness**: Checks if ANY detection matches the true BCG
- **Purity**: Ratio of correct detections to total detections across all images

### Single-Prediction Analysis (Traditional Models)

For models that generate exactly one prediction per image:
- **Completeness** = **Purity** (since each image has exactly one prediction)

## File Structure

```
bcg_candidate_classifier/
├── plot_completeness_purity.py        # Main plotting module
├── test_completeness_purity.py        # Standalone test script
├── enhanced_full_run.py               # Modified to include C&P plots (lines 723-729, 808-809)
└── COMPLETENESS_PURITY_README.md      # This file
```

## Example Output

When successfully generated, you'll see output like:

```
Loaded 157 evaluation results
Loaded 3524 BCG catalog entries
Matched delta_mstar_z for 157/157 samples
Using multi-detection analysis (UQ model)
Average detections per image: 4.23
Completeness and purity plots saved to: .../completeness_purity_plots.png
High-quality PDF saved to: .../completeness_purity_plots.pdf
```

## Notes

- The plots are saved in **both PNG and PDF** formats for maximum flexibility
- PDF files are suitable for publications and presentations
- If `delta_mstar_z` cannot be matched from the BCG CSV, those subplots will show "No data available"
- The distance threshold for "successful detection" is configurable (default: 10.0 pixels)
- All plotting parameters (bins, threshold, figure size) can be customized via command-line arguments

## Troubleshooting

### "No delta_mstar_z data available"

**Solution**: Provide the correct BCG CSV path using `--bcg_csv` argument:
```bash
python plot_completeness_purity.py evaluation_results.csv \
    --bcg_csv /path/to/bcgs_3p8arcmin_clean_matched.csv
```

### "No redshift data available"

**Cause**: The evaluation results were generated without metadata.

**Solution**: Re-run `test.py` with the `--use_bcg_data` flag to include metadata in the results.

### Different completeness and purity values

**Expected**: For UQ models with multiple detections per image, completeness and purity can differ:
- Completeness: "Did we find the true BCG among our detections?"
- Purity: "What fraction of all our detections are correct?"

For single-prediction models, they will always be equal.

## Contact

For questions or issues, please check the main BCG classifier documentation or create an issue in the project repository.
