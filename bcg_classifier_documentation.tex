\documentclass[twocolumn,10pt]{aastex631}

% ---------- Packages ----------
\usepackage{amsmath,amssymb}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}

\usepackage{tikz}
\usetikzlibrary{arrows.meta,positioning,fit,calc,backgrounds}

\shorttitle{BCG Candidate Classification with Uncertainty Quantification}
\shortauthors{Machine Learning Documentation}

\begin{document}

\title{Machine Learning Architecture for Brightest Cluster Galaxy Candidate Classification: A Multi-Modal Approach with Color Features, Uncertainty Quantification, and DES Prior Integration}

\author{Documentation of Implementation}
\affiliation{High Energy Physics Image Marker Project}

\begin{abstract}
We present a comprehensive machine learning framework for automated Brightest Cluster Galaxy (BCG) identification that integrates uncertainty quantification, explainable AI, and multi-modal feature analysis for large-scale astronomical surveys. Our approach employs three complementary architectures: (1) deterministic classification for baseline performance, (2) probabilistic models with Monte Carlo dropout and temperature scaling for calibrated uncertainty estimates \citep{Laves2019WellCalibratedMU,Gal2016MCDropout}, and (3) ensemble methods for robust predictions across diverse cluster environments. The system incorporates RGB color features specifically designed for red-sequence detection, addressing the critical contamination problem where bright white objects (stars, QSOs) receive spuriously high BCG probabilities in traditional grayscale-based approaches. Key innovations include SHAP-based feature importance analysis \citep{Dainotti2025InterpretableAI} that provides physical interpretation of model predictions, comprehensive uncertainty quantification enabling detection-threshold classification, and flexible integration of DES photometric priors \citep{Rykoff2016DES} alongside automatic candidate detection. The framework processes multi-scale BCG datasets (2.2' and 3.8' angular scales) with optional auxiliary features including photometric redshift and stellar mass indicators. Systematic evaluation demonstrates rank-based performance metrics, with explainable AI analysis revealing the relative importance of morphological, contextual, color, and auxiliary features for BCG identification. This interpretable, uncertainty-aware approach provides calibrated confidence estimates essential for scientific decision-making in modern survey astronomy, enabling seamless integration with existing astronomical pipelines while maintaining full traceability of model predictions.
\end{abstract}

\keywords{methods: data analysis --- galaxies: clusters: general --- techniques: image processing --- methods: statistical}

\section{Introduction}

The identification of Brightest Cluster Galaxies (BCGs) represents a fundamental challenge in extragalactic astronomy, requiring integration of photometric, morphological, and contextual information. Traditional approaches relying on manual inspection or simple brightness-based selection become computationally prohibitive for modern large-scale surveys such as the Dark Energy Survey (DES) \citep{Rykoff2016}.

\subsection{Historical Context of Feature Extraction in Astronomical Machine Learning}

The evolution of feature extraction methods in astronomy has undergone significant transformation over the past two decades. Early quantitative approaches to galaxy morphology relied heavily on handcrafted features, most notably the CAS system (Concentration, Asymmetry, Smoothness) introduced by \citet{Abraham1996} and later extended by \citet{Conselice2003}. These parametric measures provided objective quantification of galaxy structure, enabling systematic morphological classification across large datasets such as the Sloan Digital Sky Survey (SDSS).

The CAS parameters represent the foundational paradigm of engineered feature extraction in astronomical applications. Concentration measures the central light distribution, asymmetry quantifies rotational symmetry deviations, and smoothness captures small-scale structural irregularities \citep{Conselice2003}. Extensions to this system included Gini coefficients and $M_{20}$ moments \citep{Hambleton2011}, creating comprehensive morphometric frameworks that enabled robust statistical analysis of galaxy populations.

Traditional feature engineering approaches demonstrated remarkable success in characterizing galaxy morphologies and enabled discoveries about galaxy evolution across cosmic time \citep{Conselice2014}. However, these methods required extensive domain expertise to design appropriate features and often failed to capture subtle morphological variations that might be astronomically significant.

The paradigm shifted dramatically with the advent of deep learning approaches in the 2010s, where convolutional neural networks (CNNs) began extracting features automatically through hierarchical representation learning \citep{Dieleman2015}. This transition from handcrafted to learned features marked a fundamental change in astronomical data analysis, enabling detection of patterns beyond human-engineered parametrizations.

\subsection{Contemporary Challenges and Hybrid Approaches}

Recent work in BCG detection reflects this methodological evolution. \citet{Janulewicz2025BCG} demonstrated that neural networks can achieve 95\% accuracy in automated BCG identification using purely data-driven approaches, while \citet{COSMIC2024} developed the COSMIC algorithm combining traditional clustering methods with machine learning techniques for improved cluster detection.

However, purely data-driven approaches face significant challenges in astronomical contexts. Deep learning models often lack interpretability crucial for scientific validation, require extensive training data that may not be available for rare astronomical objects, and can struggle with domain adaptation across different surveys or instruments. Furthermore, the physical understanding embedded in traditional parametric features remains valuable for incorporating known astrophysical relationships.

\subsection{The Case for Hybrid Feature Integration}

Our approach addresses these limitations by implementing a hybrid framework that combines the interpretability and physical grounding of engineered features with the flexibility of modern machine learning architectures. This methodology enables incorporation of auxiliary astronomical measurements (redshift, stellar mass indicators) that provide crucial physical context unavailable to purely image-based approaches.

The integration of uncertainty quantification through Monte Carlo dropout \citep{Laves2019WellCalibratedMU} and temperature scaling addresses a critical gap in astronomical machine learning applications, where quantified confidence estimates are essential for scientific decision-making and pipeline integration in large-scale surveys.

We present a machine learning framework that reformulates BCG identification as a candidate classification problem, providing both deterministic rankings and probabilistic outputs with uncertainty quantification. Our approach naturally handles the discrete nature of galaxy identification while incorporating diverse astronomical data products, bridging traditional parametric methods with modern probabilistic inference techniques.

\section{System Architecture}

Figure~\ref{fig:architecture} presents the complete machine learning pipeline, illustrating data flow from optical inputs through candidate selection, feature extraction, neural network processing, and probabilistic inference.

% =========================================================
% Figure: Two-row layout matching actual Python implementation
% =========================================================


\begin{figure*}[t]
\centering
\resizebox{\textwidth}{!}{
\begin{tikzpicture}[
  font=\footnotesize,
  node distance=6mm and 9mm,
  >=Latex,
  every node/.style={align=center},
  box/.style={rounded corners=2pt, draw=black!60, very thin, fill=white, inner sep=2.5pt},
  data/.style={box},
  optdata/.style={box, dashed},         % optional data boxes (dashed border)
  proc/.style={box},
  feat/.style={box},
  optfeat/.style={box, dashed},         % optional feature boxes (dashed border)
  nn/.style={box},
  outbox/.style={box},                  % avoid TikZ 'out' key name
  reqedge/.style={-Latex, semithick, draw=black!85},
  optedge/.style={-Latex, semithick, dashed, draw=black!85},
  panel/.style={rounded corners=3pt, draw=black!35, line width=0.6pt, inner sep=3.5mm, fill opacity=0.90},
  ptitle/.style={font=\bfseries\footnotesize, text=black!65, fill=white, inner sep=1pt}
]
\def\vsep{3.2mm} % uniform vertical gap

% -------------------- FIRST ROW: Inputs, Detection, Features --------------------
% Columns: Inputs (x=0), Detection (x=4.0), Features (x=8.4)

% INPUTS
\begin{scope}[xshift=0cm, yshift=0cm]
  \node[data,    text width=2.45cm] (Opt) at (0, 1.50) {\textbf{Optical Images}\\BCG 2.2$'$ or 3.8$'$};
  \node[optdata, text width=2.45cm] (SN)   [below=\vsep of Opt] {\textbf{S/N Maps $z$}\\(optional)};
  \node[optdata, text width=2.45cm] (Z)   [below=\vsep of SN] {\textbf{Redshift $z$}\\(global; optional)};
  \node[optdata, text width=2.45cm] (Delta)   [below=\vsep of Z] {\textbf{$\Delta m^*_z$}\\(stellar mass; optional)};
\end{scope}

% CANDIDATE DETECTION
\begin{scope}[xshift=4.0cm, yshift=0cm]
  \node[proc, text width=3.05cm] (Det) at (0, 1.25)
    {\textbf{Local Maxima}\\$d_{\min}=8$, $\theta_{\mathrm{rel}}=0.1$\\NMS + filtering};
  \node[proc, text width=3.05cm, dashed, draw=black!55] (DES) [below=\vsep of Det]
    {\textbf{DES Prior Candidates}\\Photometric catalog\\$\Delta m^*_z$ filtering};
  \node[proc, dashed, text width=3.05cm] (RedM) [below=\vsep of DES]
    {\textbf{RedMapper \\ Probabilities}\\(training-mode only, \\optional)};

  % Input connections to detection (clean routes)
  \path[reqedge] (Opt.east) -- (Det.west);
  \path[optedge] (Opt.east) to[out=0,in=160] (DES.160);
  \path[optedge] (Delta.east) -- (DES.west);
\end{scope}

% FEATURE EXTRACTION (slightly lowered; includes patch-based features)
\begin{scope}[xshift=8.4cm, yshift=-14mm]
  \node[feat, text width=3.55cm] (Patch)  at (0, 2.4) {\textbf{Patch Features}\\$64 \times 64$ windows\\Radial profiles, gradients\\Intensity statistics};
  \node[optfeat, text width=3.55cm] (Color) [below=\vsep of Patch] {\textbf{Color Features}\\RGB color ratios\\Red-sequence indicators\\PCA dimensionality reduction};
  \node[feat,    text width=3.55cm] (Context) [below=\vsep of Color]  {\textbf{Context Features}\\Position, candidate density\\Brightness rank, background};
  \node[optfeat,    text width=3.55cm] (Aux) [below=\vsep of Context] {\textbf{Auxiliary Features}\\Redshift $z$, $\Delta m^*_z$\\(when available)};
\end{scope}

% -------------------- SECOND ROW: Fusion & Classification (fully below row-1) --------------------
\begin{scope}[xshift=40mm, yshift=-70mm]  % set well below row-1 to avoid overlap
  % Fusion
  \node[nn, text width=3.65cm] (Fusion) at (0, 2.2)
    {\textbf{Feature Fusion}\\StandardScaler\\$\mathbf{f}_i \in \mathbb{R}^{38-58}$};

  % Classifier with correct architecture
  \node[nn, text width=3.65cm] (CLS) [below=\vsep of Fusion]
    {\textbf{MLP Classifier}\\$[128, 64, 32]$ + ReLU\\Dropout $\rho = 0.2$};

  % Outputs (deterministic and probabilistic)
  \node[outbox, text width=2.05cm] (Score) [below left=\vsep and 3mm of CLS] {\textbf{Score $s_i$}\\(deterministic)};
  \node[outbox, text width=2.05cm] (Prob)  [below right=\vsep and 3mm of CLS] {\textbf{Prob.\ $p_i$}\\temp.\ scaled\\MC dropout};

  % Decision centered below
  \node[outbox, text width=3.65cm] (Dec) [below=\vsep of $(Score.south)!0.5!(Prob.south)$]
    {\textbf{BCG Prediction}\\$\argmax_i\,s_i$ or $\argmax_i\,p_i$\\confidence \& $\mathrm{Var}[p_i]$};

  % Inside-panel flow
  \path[reqedge] (Fusion) -- (CLS);
  \path[reqedge] (CLS.south) |- (Score.east);
  \path[optedge] (CLS.south) |- (Prob.west);
  \path[reqedge] (Score.south) |- (Dec.west);
  \path[optedge] (Prob.south) |- (Dec.east);

  % Background panel and title (inside)
  \begin{pgfonlayer}{background}
    \node[panel, fill=purple!30, fit=(Fusion)(CLS)(Score)(Prob)(Dec)] (PFuse) {};
  \end{pgfonlayer}
  \node[ptitle, anchor=west] at ($(PFuse.north west)+(2mm,-1.5mm)$) {BCG Classification};
\end{scope}

% ==================== STAGE PANELS (ROW-1) & TITLES ====================
\begin{pgfonlayer}{background}
  \node[panel, fill=red!20,  fit=(Opt)(Z)(Delta)]                              (PIn)   {};
  \node[panel, fill=green!20, fit=(Det)(DES)(RedM)]                              (PDet)  {};
  \node[panel, fill=blue!20,fit=(Patch)(Color)(Context)(Aux)]            (PFeat) {};
\end{pgfonlayer}
\node[ptitle, anchor=west] at ($(PIn.north west)+(2mm,-1.7mm)$)   {Input Data};
\node[ptitle, anchor=west] at ($(PDet.north west)+(2mm,-1.5mm)$)  {Candidate Detection};
\node[ptitle, anchor=west] at ($(PFeat.north west)+(2mm,-1.5mm)$) {Feature Extraction};

% ===== Connections between Detection -> Feature Extraction (to panel edge, non-overlapping) =====
\path[reqedge] (Det.east)  to[out=0,in=180] ($(PFeat.west)+(0,6mm)$);
\path[optedge] (DES.east)   to[out=0,in=180] ($(PFeat.west)+(-0.0,-6mm)$);

% ===== Optional auxiliary features -> Feature Extraction (long dashed, elbow; avoids labels) =====
\coordinate (Zmid) at ($(Z.east)+(1.0,0)$);
\path[optedge] (Z.east) -- (Zmid) |- (Aux.west);
\coordinate (Deltamid) at ($(Delta.east)+(0.8,0)$);
\path[optedge] (Delta.east) -- (Deltamid) |- (Aux.west);

% ===== Single arrow from bottom of Feature Extraction panel -> Feature Fusion =====
\path[reqedge] (PFeat.south) |- (Fusion.east);

% ==================== LEGEND ====================
\node[draw=none, anchor=west] (LegTitle) at ($(Delta.south west)+(-5mm,-7mm)$) {\textbf{Legend:}};
\draw[reqedge] (LegTitle.east) ++(3mm,0) -- ++(10mm,0) node[right, black] {\footnotesize required};
\draw[optedge] (LegTitle.east) ++(3mm,-4mm) -- ++(10mm,0) node[right, black] {\footnotesize optional};

\end{tikzpicture}%
} % end resizebox


\caption{Multi-modal BCG candidate classification architecture. The system processes optical astronomical data from BCG datasets through candidate selection (automatic local maxima detection or DES photometric priors), comprehensive multi-modal feature extraction (morphological, contextual, color, and auxiliary features), neural network classification with optional uncertainty quantification, and probabilistic inference. The color feature extraction specifically targets red-sequence cluster galaxies, addressing critical failure modes from bright white contaminant sources. Solid arrows indicate required components; dashed arrows show optional enhancements available based on data configuration. The framework supports both 2.2' and 3.8' scale BCG datasets with optional color features and auxiliary measurements (redshift, stellar mass indicators).}
\label{fig:architecture}
\end{figure*}



\section{Methodology}

\subsection{Problem Formulation}

Rather than treating BCG identification as coordinate regression, we formulate it as a candidate ranking and classification task. Given a multi-band optical image $\mathbf{I} \in \mathbb{R}^{H \times W \times C}$ (typically RGB) and optional auxiliary measurements $\mathbf{a} \in \mathbb{R}^{D_a}$ (redshift, stellar mass indicators), our objective is to:

\begin{enumerate}
\item Identify candidate locations $\mathcal{C} = \{(x_i, y_i)\}_{i=1}^{N}$ via automatic detection or prior catalogs
\item Extract multi-modal feature representations $\mathbf{f}_i \in \mathbb{R}^{D}$ for each candidate, incorporating morphological, contextual, and optional color information
\item Classify each candidate with score $s_i$ (deterministic) or probability $p_i = P(\text{BCG}|\mathbf{f}_i)$ (probabilistic)
\item Select the highest-scoring candidate as the BCG prediction
\end{enumerate}

This formulation enables direct uncertainty quantification, natural handling of ambiguous cases, and principled integration of diverse observational constraints.

\subsection{Data Integration}

Our framework processes optical imaging data from BCG datasets at two angular scales:

\subsubsection{BCG Datasets}
The system supports BCG images at two scales:
\begin{itemize}
\item \textbf{2.2 arcminute scale}: Higher resolution images suitable for nearby clusters
\item \textbf{3.8 arcminute scale}: Wider field images accommodating more distant systems
\end{itemize}

Images are stored as multi-frame TIFF files with embedded WCS (World Coordinate System) information for astrometric calibration.

\subsubsection{Auxiliary Astronomical Measurements}
The system incorporates auxiliary measurements as global features:
\begin{itemize}
\item \textbf{Photometric Redshift}: $z$ provides distance and evolutionary context
\item \textbf{Stellar Mass Indicator}: $\Delta m^*_z$ represents magnitude difference from characteristic stellar mass, providing crucial constraints on galaxy properties
\end{itemize}

\subsection{Candidate Selection Strategies}

The framework supports two distinct candidate identification approaches:

\subsubsection{Automatic Candidate Detection}

The automatic detection system employs a multi-stage pipeline for identifying candidate BCG locations based on local intensity maxima, following established approaches in astronomical source detection \citep{Bertin1996}. This method adapts traditional peak-finding algorithms commonly used in photometric catalogs to the specific requirements of BCG identification within cluster environments.

\textbf{Preprocessing and Image Standardization}: The pipeline begins with image preprocessing to ensure consistent input format. For traditional morphological feature extraction, multi-band RGB images are converted to grayscale using standard luminance weighting:
\begin{equation}
L = 0.299 \cdot R + 0.587 \cdot G + 0.114 \cdot B
\end{equation}
This conversion preserves the primary luminosity information crucial for identifying the brightest objects while reducing computational complexity. However, this grayscale conversion introduces a critical information loss problem: chromatic information essential for distinguishing red-sequence cluster galaxies from bright white contaminant sources (stars, QSOs) is discarded. To address this fundamental limitation, our framework implements optional RGB color feature extraction that preserves essential chromatic information while maintaining computational efficiency through dimensionality reduction techniques.

\textbf{Local Maxima Detection}: The core detection mechanism employs a 3×3 maximum filter implemented through \texttt{scipy.ndimage.maximum\_filter}, creating a binary mask where each pixel equals the maximum value in its local neighborhood. This approach identifies local intensity peaks while maintaining computational efficiency suitable for large-scale processing:
\begin{equation}
M(x,y) = \begin{cases} 
1 & \text{if } I(x,y) = \max_{(i,j) \in \mathcal{N}_3(x,y)} I(i,j) \\
0 & \text{otherwise}
\end{cases}
\end{equation}
where $\mathcal{N}_3(x,y)$ represents the 3×3 neighborhood centered at pixel $(x,y)$.

\textbf{Adaptive Intensity Thresholding}: To minimize spurious detections from noise and faint background sources, the system applies a relative intensity threshold $\theta_{\text{rel}} = 0.1$ (default) scaled by the image maximum:
\begin{equation}
T_{\text{abs}} = \theta_{\text{rel}} \cdot \max(\mathbf{I})
\end{equation}
Only local maxima exceeding this threshold are retained as candidate locations. This adaptive approach automatically adjusts to varying image dynamic ranges across different observations and survey depths.

\textbf{Border Exclusion}: Candidates within 30 pixels (default) of image boundaries are systematically removed to avoid edge artifacts and incomplete photometric measurements that could compromise feature extraction. This exclusion zone ensures sufficient context for subsequent patch-based feature computation.

\textbf{Non-Maximum Suppression (NMS)}: The final stage implements a greedy NMS algorithm to enforce spatial separation constraints and prevent multiple detections of the same astronomical object. Candidates are processed in descending brightness order, with each candidate retained only if it lies more than $d_{\min} = 8$ pixels from all previously selected candidates:
\begin{equation}
d_{ij} = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2} > d_{\min}
\end{equation}
This distance constraint reflects typical seeing conditions and prevents over-sampling of extended sources.

The algorithm terminates when either the desired number of candidates (\texttt{max\_candidates = 50}) is reached or all remaining maxima have been processed. This systematic approach ensures robust candidate identification while maintaining computational tractability for large datasets.

\subsubsection{DES Photometric Prior Candidates}

For datasets with existing photometric catalogs, our framework leverages pre-computed candidate selections from established astronomical pipelines, particularly the Dark Energy Survey (DES) photometric catalog and RedMapper cluster finder \citep{Rykoff2014redMaPPer,Rykoff2016}. This approach represents a paradigm shift from purely image-based detection to integration with existing astronomical knowledge products.

\textbf{RedMapper Integration and Red-Sequence Selection}: The RedMapper algorithm provides a sophisticated foundation for BCG candidate identification through its red-sequence cluster finding methodology \citep{Rykoff2014redMaPPer}. RedMapper identifies galaxy clusters by detecting overdensities of red-sequence galaxies at specific photometric redshifts, simultaneously providing estimates of cluster richness, photometric redshift, and preliminary BCG candidates. Our implementation utilizes RedMapper's BCG probability assignments during training supervision while carefully excluding these probabilities from inference features to prevent data leakage.

\textbf{Stellar Mass Filtering via $\Delta m^*_z$ Criteria}: A critical component of the DES prior approach involves filtering candidates based on the stellar mass indicator $\Delta m^*_z$, which represents the magnitude difference from the characteristic stellar mass at a given redshift \citep{Rykoff2016}. This parameter provides powerful constraints on galaxy selection by identifying objects with stellar masses consistent with BCG populations:
\begin{equation}
\Delta m^*_z = m_i - m^*(z)
\end{equation}
where $m_i$ is the observed magnitude of candidate $i$ and $m^*(z)$ is the characteristic magnitude corresponding to the break in the galaxy luminosity function at redshift $z$.

Candidates with $\Delta m^*_z$ values consistent with massive galaxy populations (typically $\Delta m^*_z < 1.0$) are preferentially retained, effectively pre-selecting objects with stellar masses appropriate for BCG identification. This filtering reduces the candidate pool size while maintaining high completeness for genuine BCGs.

\textbf{Computational Efficiency and Pipeline Integration}: The DES prior approach offers significant computational advantages over exhaustive image-based detection. By leveraging pre-existing photometric catalogs, the method reduces candidate detection overhead and enables seamless integration with established astronomical data products and quality flags. This integration facilitates systematic cross-validation with existing cluster catalogs and enables incorporation of additional metadata such as photometric redshift estimates and cluster richness measurements.

\textbf{Multi-Scale Compatibility}: DES photometric priors maintain consistency across different angular scales (2.2' and 3.8' BCG images) through coordinate transformation and proper motion corrections. The catalog-based approach naturally accommodates varying survey depths and observing conditions, providing robust candidate selection across diverse observational parameters.

This hybrid approach combines the reliability of established astronomical pipelines with the flexibility required for machine learning applications, enabling systematic BCG identification while maintaining compatibility with existing survey infrastructure and data products.

\subsection{Feature Extraction}

For each candidate location $(x_i, y_i)$, we extract comprehensive feature vectors combining local morphological information with global contextual constraints. Our feature extraction methodology draws inspiration from traditional galaxy morphology analysis \citep{Conselice2003} while incorporating domain-specific adaptations for BCG identification in cluster environments.

\subsubsection{Patch-Based Morphological Features}

Fixed-size square patches $\mathbf{P}_i \in \mathbb{R}^{64 \times 64 \times C}$ are extracted around each candidate location, providing local morphological characterization essential for BCG discrimination. The 64×64 pixel patch size ensures adequate spatial coverage while maintaining computational efficiency for large-scale processing.

\textbf{Intensity Distribution Statistics}: The foundation of our patch-based features consists of fundamental intensity moments that characterize the brightness distribution within each candidate region. Following established practices in astronomical photometry \citep{Bertin1996}, we compute:
\begin{align}
\mu_I &= \frac{1}{N} \sum_{p \in \mathbf{P}_i} I(p) \\
\sigma_I &= \sqrt{\frac{1}{N-1} \sum_{p \in \mathbf{P}_i} [I(p) - \mu_I]^2} \\
\text{skew}_I &= \frac{1}{N} \sum_{p \in \mathbf{P}_i} \left(\frac{I(p) - \mu_I}{\sigma_I}\right)^3
\end{align}
where $N$ is the number of pixels in the patch. Additional statistics include maximum, minimum, and median intensities, providing robust characterization of the local brightness distribution.

\textbf{Concentration Analysis}: Adapting the concentration parameter from the CAS system \citep{Conselice2003}, we implement a simplified concentration measure based on central versus peripheral intensity distributions. The central region consists of a 16×16 pixel area centered on the candidate, while the peripheral region encompasses the remaining patch area:
\begin{equation}
C_{\text{local}} = \frac{\mu_I^{\text{central}}}{\mu_I^{\text{peripheral}} + \epsilon}
\end{equation}
where $\epsilon = 10^{-8}$ prevents division by zero. This ratio effectively discriminates between centrally concentrated sources (typical of BCGs) and more diffuse or irregular objects.

\textbf{Gradient and Edge Analysis}: Surface brightness gradients provide crucial information about galaxy morphology and structural properties. We compute gradient magnitude fields using finite differences:
\begin{align}
G_x(i,j) &= \frac{\partial I}{\partial x} \approx I(i+1,j) - I(i-1,j) \\
G_y(i,j) &= \frac{\partial I}{\partial y} \approx I(i,j+1) - I(i,j-1) \\
|\mathbf{G}|(i,j) &= \sqrt{G_x(i,j)^2 + G_y(i,j)^2}
\end{align}
Statistical measures of the gradient magnitude field (mean, standard deviation, maximum) characterize edge strength and morphological complexity, enabling discrimination between smooth elliptical profiles typical of BCGs and more irregular morphologies.

\textbf{Geometric Moments and Shape Analysis}: We compute intensity-weighted geometric moments to quantify morphological asymmetry and structural properties, following established practices in quantitative morphology \citep{Hambleton2011}. For a patch with intensity distribution $I(x,y)$ and total intensity $I_{\text{total}}$, we calculate:
\begin{align}
\bar{x} &= \frac{\sum_{i,j} x_{i,j} I(i,j)}{I_{\text{total}}}, \quad \bar{y} = \frac{\sum_{i,j} y_{i,j} I(i,j)}{I_{\text{total}}} \\
\mu_{20} &= \frac{\sum_{i,j} (x_{i,j} - \bar{x})^2 I(i,j)}{I_{\text{total}}} \\
\mu_{02} &= \frac{\sum_{i,j} (y_{i,j} - \bar{y})^2 I(i,j)}{I_{\text{total}}} \\
\mu_{11} &= \frac{\sum_{i,j} (x_{i,j} - \bar{x})(y_{i,j} - \bar{y}) I(i,j)}{I_{\text{total}}}
\end{align}
From these moments, we derive an eccentricity measure:
\begin{equation}
e = \frac{\sqrt{(\mu_{20} - \mu_{02})^2 + 4\mu_{11}^2}}{\mu_{20} + \mu_{02} + \epsilon}
\end{equation}
This parameter quantifies departure from circular symmetry, with BCGs typically exhibiting moderate eccentricity values consistent with elliptical morphologies.

\subsubsection{Contextual and Environmental Features}

Beyond local morphological analysis, our framework incorporates contextual features that capture environmental information crucial for BCG identification within cluster contexts.


\textbf{Directional Intensity Sampling}: We implement directional sampling along four cardinal directions (North, East, South, West) extending outward from each candidate location. For each direction, intensity values are sampled at regular intervals up to half the patch size, providing:
\begin{equation}
\mu_{\text{dir}} = \frac{1}{N_{\text{dir}}} \sum_{k=1}^{N_{\text{dir}}} I(x_c + k\Delta x, y_c + k\Delta y)
\end{equation}
where $(\Delta x, \Delta y)$ represents the unit direction vector. This approach captures asymmetric features and environmental gradients that may influence BCG identification.

\textbf{Spatial Position Encoding}: Absolute positions within the image frame are normalized and encoded as features:
\begin{align}
x_{\text{rel}} &= \frac{x_i - W/2}{W/2} \in [-1, 1] \\
y_{\text{rel}} &= \frac{y_i - H/2}{H/2} \in [-1, 1] \\
r_{\text{center}} &= \sqrt{x_{\text{rel}}^2 + y_{\text{rel}}^2}
\end{align}
where $(W, H)$ are image dimensions. This encoding enables the model to learn spatial biases in BCG distribution within the image field of view.

\subsubsection{Auxiliary Feature Integration}

When auxiliary astronomical measurements are available, they are incorporated through concatenation with morphological and contextual features:
\begin{equation}
\mathbf{f}_i = [\mathbf{f}_i^{\text{patch}}, \mathbf{f}_i^{\text{context}}, \mathbf{a}]
\end{equation}
where $\mathbf{a}$ includes redshift $z$ and stellar mass indicator $\Delta m^*_z$.

\textbf{Redshift Integration}: Photometric redshift estimates provide cosmological distance constraints that inform expected BCG properties. Redshift values are normalized to the typical range $z \in [0.1, 1.2]$ observed in our datasets.

\textbf{Stellar Mass Indicators}: The $\Delta m^*_z$ parameter encodes crucial information about stellar mass relative to the characteristic mass at a given redshift, providing powerful constraints on BCG candidacy based on established scaling relations in cluster astrophysics.

The complete feature vector comprises approximately 38-58 dimensions (depending on color features and auxiliary data availability), providing comprehensive characterization of each candidate while maintaining computational tractability for large-scale applications. Features are standardized using \texttt{sklearn.preprocessing.StandardScaler} to ensure equal contribution across different scales and units.

\subsubsection{RGB Color Feature Extraction for Red-Sequence Detection}

A critical innovation in our framework addresses the fundamental limitation of grayscale-based analysis: the inability to distinguish between red-sequence cluster galaxies and bright white contaminant sources. Traditional approaches converting RGB images to grayscale through luminance weighting (Equation~1) discard essential chromatic information that enables discrimination between genuine BCG candidates and bright stars or quasi-stellar objects (QSOs) that often contaminate photometric catalogs.

\textbf{Motivation and Failure Mode Analysis}: Empirical analysis of BCG classification failures reveals a systematic bias toward bright white objects receiving spuriously high BCG probabilities. This occurs because traditional morphological and intensity-based features cannot distinguish between:
\begin{itemize}
\item Genuine red-sequence BCGs with $g-r \approx 1.2-1.6$ colors typical of evolved stellar populations \citep{Bell2004,Bruzual2003}
\item Bright foreground stars with $g-r \approx 0.0-0.4$ exhibiting white/blue colors
\item Background QSOs with broad-band colors often resembling stellar objects
\end{itemize}

Our color feature extraction system directly addresses this contamination by preserving and analyzing RGB chromatic information that becomes invisible in grayscale conversion.

\textbf{Color Ratio Analysis for Red-Sequence Identification}: The core of our color feature system implements photometric color analysis adapted for RGB imaging data. While lacking the precision of calibrated multi-band photometry, RGB data provides sufficient chromatic information for red-sequence detection when analyzed through appropriate color ratios.

We extract fundamental color measurements that approximate standard photometric indices:
\begin{align}
\text{R/G ratio} &= \frac{\langle I_R \rangle}{\langle I_G \rangle + \epsilon} \quad \text{(approximates } r-g \text{ color)} \\
\text{R/B ratio} &= \frac{\langle I_R \rangle}{\langle I_B \rangle + \epsilon} \quad \text{(approximates } r-i \text{ color)} \\
\text{Color magnitude} &= \frac{\langle\sqrt{(I_R-I_G)^2 + (I_G-I_B)^2 + (I_R-I_B)^2}\rangle}{\langle I_R + I_G + I_B \rangle + \epsilon} \nonumber \\
&\quad \text{(departure from achromatic colors)}
\end{align}
where $\langle \cdot \rangle$ denotes spatial averaging over the candidate patch and $\epsilon = 10^{-8}$ prevents division by zero.

The color magnitude parameter quantifies departure from achromatic (white) colors, with higher values indicating more chromatic objects. This measure effectively discriminates between colored galaxies and white stellar sources.

\textbf{Red-Sequence Scoring}: We implement a red-sequence indicator specifically designed to identify objects with colors consistent with evolved stellar populations characteristic of BCGs:
\begin{equation}
S_{\text{red}} = \frac{\langle I_R - 0.5(I_G + I_B) \rangle}{\langle I_R + I_G + I_B \rangle + \epsilon}
\end{equation}
This score achieves maximum values for objects with enhanced red channel intensity relative to green and blue components, characteristic of red-sequence galaxies with prominent 4000~Å breaks and minimal ongoing star formation \citep{Kodama1997,Gladders2000}.

\textbf{Spatial Color Variation Analysis}: Beyond global color properties, our system analyzes spatial color variation within each candidate patch to distinguish genuine extended sources from point-like contaminants. We compute color uniformity measures:
\begin{align}
\sigma_{R/G} &= \text{std}\left(\frac{I_R(x,y)}{I_G(x,y) + \epsilon}\right) \\
\sigma_{R/B} &= \text{std}\left(\frac{I_R(x,y)}{I_B(x,y) + \epsilon}\right)
\end{align}
where the standard deviation is computed over all pixels within the candidate patch.

Extended galaxies typically exhibit gradual color gradients due to stellar population variations with radius, while point sources (stars) show color variations dominated by noise and PSF effects. This spatial color analysis provides additional discrimination power beyond global color measurements.

\textbf{Color Gradient Analysis}: We implement color gradient analysis to capture structural information unavailable in intensity-based morphological features:
\begin{align}
\mathbf{G}_R &= \nabla I_R, \quad \mathbf{G}_G = \nabla I_G, \quad \mathbf{G}_B = \nabla I_B \\
\rho_{RG} &= \text{corr}(|\mathbf{G}_R|, |\mathbf{G}_G|) \\
\rho_{RB} &= \text{corr}(|\mathbf{G}_R|, |\mathbf{G}_B|)
\end{align}
High correlations between color channel gradients indicate coherent morphological structure, while low correlations suggest noise-dominated or composite sources.

\textbf{Convolution-Based Color Pattern Recognition}: To capture subtle color patterns beyond simple ratios, we implement convolution-based feature extraction using predefined kernels:
\begin{align}
K_{\text{edge}} &= \begin{pmatrix} -1 & -1 & -1 \\ -1 & 8 & -1 \\ -1 & -1 & -1 \end{pmatrix}, \quad 
K_{\text{smooth}} = \frac{1}{16}\begin{pmatrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{pmatrix} \\
F_{c,k} &= \text{mean}(|I_c * K_k|) \nonumber \\
&\quad c \in \{R,G,B\}, \; k \in \{\text{edge}, \text{smooth}, \text{Laplacian}\}
\end{align}
These convolution responses capture channel-specific morphological characteristics that complement global color statistics.

\textbf{Principal Component Analysis for Dimensionality Reduction}: The complete color feature extraction generates approximately 50+ individual measurements per candidate. To maintain computational efficiency while preserving essential chromatic information, we implement Principal Component Analysis (PCA) with retention of the first 8 principal components, typically capturing $>95\%$ of the total variance.

The PCA transformation is fitted during training using color features from all training candidates:
\begin{equation}
\mathbf{f}_{\text{color}}^{\text{reduced}} = \mathbf{W}_{\text{PCA}}^T (\mathbf{f}_{\text{color}}^{\text{raw}} - \boldsymbol{\mu}_{\text{color}})
\end{equation}
where $\mathbf{W}_{\text{PCA}} \in \mathbb{R}^{50 \times 8}$ contains the first 8 principal components and $\boldsymbol{\mu}_{\text{color}}$ is the mean color feature vector.

This dimensionality reduction maintains the most informative color information while preventing feature space explosion and ensuring computational tractability for large-scale applications.

\textbf{Integration with Morphological Features}: Color features are concatenated with existing morphological and contextual features through the feature fusion mechanism:
\begin{equation}
\mathbf{f}_i^{\text{complete}} = [\mathbf{f}_i^{\text{morphological}}, \mathbf{f}_i^{\text{contextual}}, \mathbf{f}_i^{\text{color}}, \mathbf{a}_i]
\end{equation}
The combined feature vector provides comprehensive characterization encompassing both traditional photometric/morphological properties and essential chromatic information for red-sequence identification.

\subsection{Neural Network Architectures and Uncertainty Quantification}

Our framework implements three complementary neural network architectures designed for different deployment scenarios and uncertainty requirements:

\subsubsection{Deterministic Classifier (\texttt{BCGCandidateClassifier})}
The baseline architecture employs a multi-layer perceptron with hidden dimensions $[128, 64, 32]$, ReLU activation functions, and dropout regularization with rate $\rho = 0.2$. This model provides deterministic candidate rankings through:
\begin{equation}
s_i = f_{\theta}(\mathbf{f}_i)
\end{equation}
where $s_i$ represents the score for candidate $i$, $f_{\theta}$ is the neural network with parameters $\theta$, and $\mathbf{f}_i$ is the feature vector. The final BCG prediction selects the highest-scoring candidate: $\hat{i} = \argmax_i s_i$.

\subsubsection{Probabilistic Classifier (\texttt{BCGProbabilisticClassifier})}
The uncertainty-aware architecture extends the base model with principled uncertainty quantification through two complementary techniques:

\textbf{Monte Carlo Dropout}: Following \citet{Gal2016MCDropout}, we enable dropout during inference to approximate Bayesian inference. For $T$ forward passes with different dropout masks, we obtain:
\begin{align}
p_i^{(t)} &= \sigma(f_{\theta}(\mathbf{f}_i; \xi^{(t)})) \quad t = 1, \ldots, T \\
\bar{p}_i &= \frac{1}{T} \sum_{t=1}^T p_i^{(t)} \\
\text{Var}[p_i] &= \frac{1}{T-1} \sum_{t=1}^T (p_i^{(t)} - \bar{p}_i)^2
\end{align}
where $\xi^{(t)}$ represents the dropout mask for forward pass $t$, $\sigma$ is the sigmoid activation, $\bar{p}_i$ is the mean probability, and $\text{Var}[p_i]$ quantifies epistemic uncertainty.

\textbf{Temperature Scaling}: To ensure probability calibration, we apply temperature scaling \citep{Laves2019WellCalibratedMU} with learnable parameter $\tau$:
\begin{equation}
p_i^{\text{calibrated}} = \sigma\left(\frac{f_{\theta}(\mathbf{f}_i)}{\tau}\right)
\end{equation}
The temperature parameter $\tau$ is optimized on a validation set to minimize calibration error, ensuring that predicted probabilities accurately reflect true confidence levels.

\textbf{Detection Threshold Classification}: Unlike pure ranking approaches, the probabilistic model enables threshold-based classification:
\begin{equation}
\text{Classification}_i = \begin{cases}
\text{"Detection"} & \text{if } \bar{p}_i > \theta_{\text{det}} \\
\text{"Non-detection"} & \text{otherwise}
\end{cases}
\end{equation}
where $\theta_{\text{det}}$ is a configurable detection threshold, enabling binary classification suitable for automated survey pipelines.

\subsubsection{Ensemble Classifier (\texttt{BCGEnsembleClassifier})}
For maximum robustness, the ensemble approach combines $K$ independently trained probabilistic models:
\begin{align}
p_i^{\text{ensemble}} &= \frac{1}{K} \sum_{k=1}^K p_i^{(k)} \\
\text{Var}^{\text{ensemble}}[p_i] &= \frac{1}{K-1} \sum_{k=1}^K (p_i^{(k)} - p_i^{\text{ensemble}})^2
\end{align}
This approach captures both epistemic uncertainty (through individual model disagreement) and provides enhanced prediction reliability through model averaging.

\subsection{Explainable AI and Feature Importance Analysis}

A critical innovation in our framework is the integration of explainable artificial intelligence techniques to provide scientific interpretability and validation of model predictions. This addresses a fundamental challenge in astronomical machine learning: understanding \emph{why} a model makes specific predictions.

\subsubsection{SHAP-Based Feature Attribution}

We implement SHapley Additive exPlanations (SHAP) analysis \citep{Dainotti2025InterpretableAI} to quantify the contribution of each feature to individual predictions. For a given prediction $f(\mathbf{x})$, SHAP values $\phi_i$ satisfy:
\begin{equation}
f(\mathbf{x}) = \phi_0 + \sum_{i=1}^{M} \phi_i
\end{equation}
where $\phi_0$ is the baseline prediction (expected value over the dataset), $M$ is the number of features, and $\phi_i$ represents the marginal contribution of feature $i$ to the prediction.

\textbf{Individual Prediction Analysis}: SHAP waterfall plots reveal which specific features drive each BCG prediction, enabling validation against astronomical expectations. For example, a genuine BCG should exhibit positive contributions from red-sequence color features and central concentration measures.

\textbf{Global Feature Importance}: Aggregating SHAP values across large datasets reveals systematic feature importance patterns:
\begin{equation}
\text{Importance}_i = \frac{1}{N} \sum_{n=1}^{N} |\phi_i^{(n)}|
\end{equation}
This analysis quantifies the relative importance of morphological, color, contextual, and auxiliary feature categories.

\subsubsection{Physical Interpretation Framework}

Our analysis pipeline includes automated mapping from technical features to physical astronomical concepts:

\textbf{Morphological Features}: Patch statistics, concentration measures, and gradient analysis map to galaxy surface brightness profiles, structural parameters, and morphological classification.

\textbf{Color Features}: RGB ratios and red-sequence indicators directly relate to stellar population properties, star formation history, and cluster membership probability.

\textbf{Contextual Features}: Position and environmental measures correspond to cluster dynamics, central galaxy selection effects, and survey-specific systematics.

\textbf{Auxiliary Features}: Redshift and stellar mass indicators provide direct connections to fundamental galaxy properties and cosmological evolution.

\subsubsection{Sensitivity Analysis and Feature Ablation}

Beyond individual feature importance, our framework implements systematic sensitivity analysis:

\textbf{Permutation Importance}: Features are systematically permuted to measure performance degradation, providing model-agnostic importance estimates independent of the specific neural network architecture.

\textbf{Feature Group Analysis}: Related features (e.g., all color features) are simultaneously removed to assess the importance of entire feature categories, crucial for understanding which data products are most essential for BCG identification.

\textbf{Gradient-Based Importance}: For neural network models, gradient-based attribution methods complement SHAP analysis by revealing how small feature perturbations affect predictions.

\subsection{Training Procedures}

For each training image, we identify the candidate $j^*$ closest to ground truth coordinates:
\begin{equation}
j^* = \argmin_j \|(x_j, y_j) - (x_{\text{true}}, y_{\text{true}})\|_2
\end{equation}

When available, RedMapper BCG probabilities inform training through weighted loss functions while being explicitly excluded from inference features to prevent data leakage \citep{Rykoff2014redMaPPer}. This approach maintains scientific integrity by using external probability estimates for supervision without creating circular dependencies in the inference pipeline.

\section{Implementation Details}

The system is implemented in Python using PyTorch for neural network components, with comprehensive integration of modern machine learning and astronomical analysis libraries. The modular architecture enables flexible deployment across different observational scenarios and computational environments.

\subsection{Core Framework Components}

\textbf{Data Management}:
\begin{itemize}
\item \texttt{data.data\_read\_bcgs}: BCG dataset loading with multi-scale support (2.2' and 3.8' angular scales)
\item \texttt{data.candidate\_dataset\_bcgs}: Candidate-based dataset generation including \texttt{DESpriorBCGCandidateDataset} for photometric prior integration
\item WCS coordinate processing and multi-frame TIFF handling with proper astronomical calibration
\end{itemize}

\textbf{Feature Extraction Pipeline}:
\begin{itemize}
\item \texttt{utils.candidate\_based\_bcg}: Comprehensive candidate detection and morphological feature extraction
\item \texttt{utils.color\_features}: RGB color feature extraction with red-sequence detection and PCA dimensionality reduction
\item Automated feature scaling and standardization with proper train/test splits
\end{itemize}

\textbf{Machine Learning Models}:
\begin{itemize}
\item \texttt{ml\_models.candidate\_classifier}: \texttt{BCGCandidateClassifier} for deterministic predictions
\item \texttt{ml\_models.uq\_classifier}: \texttt{BCGProbabilisticClassifier} with Monte Carlo dropout and temperature scaling
\item \texttt{ml\_models.uq\_classifier}: \texttt{BCGEnsembleClassifier} for robust multi-model predictions
\end{itemize}

\textbf{Analysis and Interpretability}:
\begin{itemize}
\item \texttt{analysis.run\_analysis}: SHAP-based feature importance analysis with physical interpretation
\item \texttt{analysis.physical\_interpretation}: Automated mapping from technical features to astronomical concepts
\item \texttt{utils.diagnostic\_plots}: Comprehensive performance evaluation and uncertainty quantification metrics
\end{itemize}

\textbf{Visualization and Validation}:
\begin{itemize}
\item \texttt{utils.viz\_bcg}: Enhanced prediction visualization with probability labels and uncertainty estimates
\item \texttt{utils.test\_desprior\_candidates}: DES prior candidate integration and validation
\item Rank-based evaluation pipeline with astronomically relevant metrics
\end{itemize}

\subsection{Workflow Automation}

\textbf{End-to-End Pipeline}: The \texttt{enhanced\_full\_run.py} script provides interactive configuration and execution of the complete analysis pipeline, from data loading through model training, evaluation, and interpretability analysis.

\textbf{Scientific Integrity Validation}: Automated checks ensure proper separation of training supervision and inference features, preventing data leakage while maintaining scientific rigor.

\textbf{Results Organization}: Systematic output management with CSV exports, visualization generation, and comprehensive reporting suitable for scientific publication and pipeline integration.

\section{Results and Current Capabilities}

\subsection{Model Performance and Architectures}

Our framework implements three complementary neural network architectures, each optimized for different aspects of BCG identification:

\textbf{Deterministic Classifier (\texttt{BCGCandidateClassifier})}: The baseline model provides deterministic candidate rankings using a multi-layer perceptron with hidden dimensions [128, 64, 32] and dropout regularization ($\rho = 0.2$). This architecture achieves reliable performance for standard BCG identification tasks with computational efficiency suitable for large-scale deployment.

\textbf{Probabilistic Classifier (\texttt{BCGProbabilisticClassifier})}: This advanced architecture extends the base model with uncertainty quantification capabilities through Monte Carlo dropout \citep{Gal2016MCDropout} and temperature scaling \citep{Laves2019WellCalibratedMU}. The model provides calibrated probability estimates with epistemic uncertainty quantification, enabling detection-threshold classification where candidates with probabilities exceeding configurable thresholds are classified as "detections" rather than relative rankings.

\textbf{Ensemble Classifier (\texttt{BCGEnsembleClassifier})}: For maximum robustness, the ensemble approach combines multiple trained models to provide improved uncertainty estimates and enhanced performance in challenging scenarios. This architecture is particularly valuable for scientific applications requiring high confidence in predictions.

\subsection{Uncertainty Quantification and Calibration}

A key advancement in our framework is the implementation of principled uncertainty quantification. The probabilistic models provide:

\begin{itemize}
\item \textbf{Calibrated Probabilities}: Temperature scaling ensures that predicted probabilities accurately reflect confidence levels, crucial for scientific decision-making
\item \textbf{Epistemic Uncertainty}: Monte Carlo dropout quantifies model uncertainty, distinguishing between cases where the model is confident versus uncertain
\item \textbf{Detection Thresholds}: Configurable probability thresholds enable binary classification ("detection" vs "non-detection") rather than pure ranking
\item \textbf{Variance Estimation}: Multiple forward passes provide uncertainty estimates for each prediction
\end{itemize}

\subsection{Explainable AI and Feature Importance Analysis}

Our framework incorporates comprehensive explainable AI capabilities through SHAP (SHapley Additive exPlanations) analysis \citep{Dainotti2025InterpretableAI}, providing crucial scientific interpretability:

\textbf{Individual Prediction Explanations}: SHAP waterfall plots reveal which features contribute most strongly to each individual BCG prediction, enabling validation of model reasoning against astronomical expectations.

\textbf{Global Feature Importance}: Systematic analysis across large datasets reveals the relative importance of different feature categories:
\begin{itemize}
\item \textbf{Morphological features}: Patch-based intensity statistics, concentration measures, gradient analysis
\item \textbf{Color features}: Red-sequence indicators, spatial color variation, RGB ratios
\item \textbf{Contextual features}: Spatial position, candidate density, environmental characteristics  
\item \textbf{Auxiliary features}: Photometric redshift, stellar mass indicators ($\Delta m^*_z$)
\end{itemize}

\textbf{Physical Interpretation}: The analysis pipeline automatically maps technical feature importance to physical astronomical concepts, bridging machine learning outputs with astrophysical understanding.

\subsection{Multi-Modal Feature Integration}

The system successfully integrates diverse data products:

\textbf{RGB Color Features}: Our color feature extraction addresses a fundamental limitation in BCG identification by preserving chromatic information lost in grayscale conversion. The system extracts approximately 20 color-based features including red-sequence indicators, spatial color gradients, and PCA-reduced representations, effectively discriminating between red-sequence cluster galaxies and white stellar contaminants.

\textbf{Multi-Scale Dataset Support}: The framework processes BCG datasets at both 2.2' and 3.8' angular scales, automatically adapting feature extraction to different field sizes while maintaining consistent performance.

\textbf{Auxiliary Astronomical Measurements}: When available, photometric redshift and stellar mass indicators are seamlessly integrated as additional features, providing cosmological context that enhances classification accuracy.

\subsection{Prior Integration and Candidate Selection}

The framework supports flexible candidate selection strategies:

\textbf{Automatic Detection}: Local maxima detection with non-maximum suppression provides robust candidate identification independent of external catalogs, suitable for novel surveys or validation studies.

\textbf{DES Prior Integration}: Integration with Dark Energy Survey photometric catalogs leverages established astronomical pipelines while maintaining the flexibility to apply machine learning enhancements. The \texttt{DESpriorBCGCandidateDataset} class enables seamless loading of pre-computed candidate catalogs.

\textbf{RedMapper Supervision}: RedMapper BCG probabilities inform training through loss weighting while being explicitly excluded from inference features, ensuring scientific integrity and preventing data leakage \citep{Rykoff2014redMaPPer,Cooper2025DESI}.

\subsection{Evaluation Metrics and Validation}

Our evaluation framework employs astronomically relevant metrics:

\textbf{Rank-Based Performance}: Rather than traditional classification accuracy, we evaluate rank-1, rank-2, rank-3, and rank-5 success rates, recognizing that multiple candidates may be astronomically valid BCGs.

\textbf{Distance Error Analysis}: Systematic analysis of prediction accuracy as a function of distance from ground truth, providing insights into model precision and systematic biases.

\textbf{Redshift Dependence}: Performance evaluation across different redshift ranges, crucial for understanding model applicability to diverse cosmological epochs.

\textbf{Uncertainty Calibration}: Validation that predicted uncertainties accurately reflect actual prediction accuracy, essential for scientific applications.

\subsection{Diagnostic and Visualization Capabilities}

The framework includes comprehensive diagnostic tools:

\textbf{Prediction Visualization}: Adaptive visualization showing candidate rankings with probability labels and uncertainty estimates, enabling rapid visual validation of model performance.

\textbf{Feature Importance Plots}: Automated generation of SHAP summary plots, permutation importance rankings, and physical interpretation reports.

\textbf{Performance Diagnostics}: Distance error distributions, redshift dependence analysis, and uncertainty quantification metrics provide comprehensive model validation.

\section{Conclusions and Future Directions}

We have presented a state-of-the-art machine learning framework for automated BCG identification that advances the field through three key innovations: (1) comprehensive uncertainty quantification with calibrated confidence estimates, (2) explainable AI integration providing scientific interpretability, and (3) multi-modal feature extraction addressing fundamental limitations in traditional approaches.

\subsection{Key Contributions}

\textbf{Uncertainty-Aware Predictions}: Our implementation of Monte Carlo dropout \citep{Gal2016MCDropout} and temperature scaling \citep{Laves2019WellCalibratedMU} provides calibrated probability estimates essential for scientific decision-making. The detection-threshold classification capability enables seamless integration with automated survey pipelines while maintaining quantified confidence levels.

\textbf{Scientific Interpretability}: The integration of SHAP-based explainable AI \citep{Dainotti2025InterpretableAI} addresses a critical gap in astronomical machine learning by providing physical interpretation of model predictions. This capability is essential for scientific validation and enables astronomers to understand and trust automated classification results.

\textbf{Color Feature Innovation}: Our RGB color feature extraction system solves the fundamental contamination problem where bright white objects (stars, QSOs) receive spuriously high BCG probabilities in grayscale-based approaches. The red-sequence detection capabilities, combined with spatial color analysis and PCA dimensionality reduction, enable robust discrimination between genuine cluster galaxies and contaminant sources.

\textbf{Multi-Scale Flexibility}: The framework's support for both 2.2' and 3.8' angular scale BCG datasets, combined with flexible integration of auxiliary astronomical measurements (redshift, stellar mass indicators), provides adaptability across diverse observational scenarios and survey configurations.

\textbf{Prior Integration}: Seamless integration with established astronomical data products, including DES photometric catalogs \citep{Rykoff2016DES} and RedMapper cluster finders \citep{Cooper2025DESI}, bridges traditional observational astronomy with modern machine learning while maintaining scientific integrity through proper separation of training supervision and inference features.

\subsection{Scientific Impact and Applications}

The framework addresses critical needs in modern survey astronomy by providing:

\textbf{Calibrated Uncertainty}: Essential for large-scale surveys where automated decisions must be made with quantified confidence levels, enabling optimal resource allocation and follow-up prioritization.

\textbf{Physical Validation}: SHAP-based feature importance analysis enables validation of model predictions against astronomical expectations, crucial for scientific acceptance and systematic error identification.

\textbf{Pipeline Integration}: The modular design and comprehensive API enable integration with existing astronomical software ecosystems, supporting both research applications and operational survey pipelines.

\subsection{Comparison with Recent Work}

Our approach complements and extends recent developments in automated BCG identification. While \citet{Janulewicz2025} achieved $R^2 \approx 0.94$ on simulations using purely data-driven neural networks, our framework provides additional capabilities crucial for scientific applications: uncertainty quantification, explainable predictions, and systematic validation against physical expectations. The integration of established priors \citep{Rykoff2014redMaPPer} with modern machine learning techniques provides a pathway for systematic validation and cross-comparison with existing astronomical catalogs.

\subsection{Future Directions}

\textbf{Large-Scale Survey Deployment}: The framework is well-positioned for deployment on upcoming large-scale surveys, including LSST \citep{Grandis2025LSST}, where the combination of uncertainty quantification and explainable AI will be essential for managing the massive data volumes and maintaining scientific quality.

\textbf{Multi-Wavelength Extension}: Future development could extend the color feature extraction to incorporate additional photometric bands beyond RGB, potentially improving red-sequence detection and enabling application to surveys with different filter systems.

\textbf{Deep Learning Integration}: While maintaining the interpretability advantages of feature-based approaches, future work could explore hybrid architectures combining engineered features with deep learning representations for enhanced performance in challenging cases.

The framework represents a significant advancement in scientific machine learning for astronomy, providing the interpretability, uncertainty quantification, and validation capabilities essential for trustworthy automated analysis in the era of large-scale astronomical surveys.

\begin{acknowledgments}
This documentation describes the technical implementation of the BCG candidate classification system developed for astronomical applications, integrating machine learning methods with observational astronomy constraints.
\end{acknowledgments}

\bibliographystyle{aasjournal}
\bibliography{bcg_classifier_references}

\end{document}